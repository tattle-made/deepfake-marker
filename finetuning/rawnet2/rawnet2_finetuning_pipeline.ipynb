{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d440b7-9688-40a1-95a3-2114d6fefb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets==3.3.1\n",
    "!pip install pandas==2.2.3\n",
    "!pip install numpy==1.26.4\n",
    "!pip install torch==2.5.1\n",
    "!pip install librosa==0.10.2.post1\n",
    "!pip install tqdm==4.67.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a245bba-7074-427e-8180-921e6a265aed",
   "metadata": {},
   "source": [
    "Documentation to get hf token : https://huggingface.co/docs/hub/en/security-tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8746e0a-3056-4c8a-a2b9-ba241ad42a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"nuriachandra/Deepfake-Eval-2024\", token=\"your_hf_token\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c70a56-3797-4d80-b4c8-687174628a4b",
   "metadata": {},
   "source": [
    "Access metadata from here : https://huggingface.co/datasets/nuriachandra/Deepfake-Eval-2024/resolve/main/audio-metadata-publish.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfaa03d-851a-453a-988a-d669d23d1f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./audio_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f668a5-479c-4df3-a4b6-8a890a7ee47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "import librosa\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class DeepfakeAudioDataset(Dataset):\n",
    "    def __init__(self, dataset_split, metadata_df, set_type='Train', max_len=240000):\n",
    "        self.metadata_df = metadata_df[metadata_df['Finetuning Set'] == set_type]\n",
    "        self.metadata_df = self.metadata_df.set_index('Filename')\n",
    "\n",
    "        self.dataset_split = dataset_split\n",
    "        self.max_len = max_len\n",
    "        self.valid_indices = []\n",
    "\n",
    "        for index in range(len(dataset_split)):\n",
    "            try:\n",
    "                audio_data = dataset_split[index]['audio']\n",
    "                file_name = os.path.basename(audio_data['path'])\n",
    "\n",
    "                if not os.path.exists(audio_data['path']):\n",
    "                    raise ValueError(f\"Missing file: {audio_data['path']}\")\n",
    "                if file_name not in self.metadata_df.index:\n",
    "                    raise ValueError(f\"Metadata missing for file: {file_name}\")\n",
    "                \n",
    "                _ = librosa.load(audio_data['path'], sr=None, mono=True)  # Test loading\n",
    "                self.valid_indices.append(index)\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping corrupted file at index {index}: {e}\")\n",
    "\n",
    "    def pad(self, x):\n",
    "        x_len = x.shape[0]\n",
    "        if x_len >= self.max_len:\n",
    "            return x[:self.max_len]\n",
    "        num_repeats = int(self.max_len / x_len) + 1\n",
    "        padded_x = np.tile(x, (1, num_repeats))[:, :self.max_len][0]\n",
    "        return padded_x  \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_indices)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        actual_index = self.valid_indices[index]\n",
    "        audio_data = self.dataset_split[actual_index]['audio']\n",
    "        file_name = os.path.basename(audio_data['path'])\n",
    "        \n",
    "        x_inp = self.pad(audio_data['array'])\n",
    "        x_inp = Tensor(x_inp)\n",
    "\n",
    "        label = self.metadata_df.loc[file_name, 'Ground Truth']\n",
    "        label = 1 if label == 'Real' else 0\n",
    "        \n",
    "        return x_inp, label\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Custom collate function to filter out None values from the dataset.\"\"\"\n",
    "    batch = [b for b in batch if b is not None]\n",
    "    if len(batch) == 0:\n",
    "        return None\n",
    "    return torch.utils.data.dataloader.default_collate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927f3758-e6ad-4de5-a24f-5dd26eda6bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DeepfakeAudioDataset(dataset['train'], df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74f31d5-45a7-4fd3-aab4-b8f11400c49a",
   "metadata": {},
   "source": [
    "Following Rawnet2 architecture was copied from https://github.com/asvspoof-challenge/2021/blob/main/LA/Baseline-RawNet2/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5320053e-98cd-438b-9eb2-18637639f795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from collections import OrderedDict\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "\n",
    "___author__ = \"Hemlata Tak\"\n",
    "__email__ = \"tak@eurecom.fr\"\n",
    "\n",
    "\n",
    "class SincConv(nn.Module):\n",
    "    @staticmethod\n",
    "    def to_mel(hz):\n",
    "        return 2595 * np.log10(1 + hz / 700)\n",
    "\n",
    "    @staticmethod\n",
    "    def to_hz(mel):\n",
    "        return 700 * (10 ** (mel / 2595) - 1)\n",
    "\n",
    "\n",
    "    def __init__(self, device,out_channels, kernel_size,in_channels=1,sample_rate=16000,\n",
    "                 stride=1, padding=0, dilation=1, bias=False, groups=1):\n",
    "\n",
    "        super(SincConv,self).__init__()\n",
    "\n",
    "        if in_channels != 1:\n",
    "            \n",
    "            msg = \"SincConv only support one input channel (here, in_channels = {%i})\" % (in_channels)\n",
    "            raise ValueError(msg)\n",
    "        \n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sample_rate=sample_rate\n",
    "\n",
    "        if kernel_size%2==0:\n",
    "            self.kernel_size=self.kernel_size+1\n",
    "\n",
    "        self.device=device   \n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        \n",
    "        if bias:\n",
    "            raise ValueError('SincConv does not support bias.')\n",
    "        if groups > 1:\n",
    "            raise ValueError('SincConv does not support groups.')\n",
    "        \n",
    "    \n",
    "        NFFT = 512\n",
    "        f=int(self.sample_rate/2)*np.linspace(0,1,int(NFFT/2)+1)\n",
    "        fmel=self.to_mel(f)   # Hz to mel conversion\n",
    "        fmelmax=np.max(fmel)\n",
    "        fmelmin=np.min(fmel)\n",
    "        filbandwidthsmel=np.linspace(fmelmin,fmelmax,self.out_channels+1)\n",
    "        filbandwidthsf=self.to_hz(filbandwidthsmel)  # Mel to Hz conversion\n",
    "        self.mel=filbandwidthsf\n",
    "        self.hsupp=torch.arange(-(self.kernel_size-1)/2, (self.kernel_size-1)/2+1)\n",
    "        self.band_pass=torch.zeros(self.out_channels,self.kernel_size)\n",
    "    \n",
    "       \n",
    "        \n",
    "    def forward(self,x):\n",
    "        for i in range(len(self.mel)-1):\n",
    "            fmin=self.mel[i]\n",
    "            fmax=self.mel[i+1]\n",
    "            hHigh=(2*fmax/self.sample_rate)*np.sinc(2*fmax*self.hsupp/self.sample_rate)\n",
    "            hLow=(2*fmin/self.sample_rate)*np.sinc(2*fmin*self.hsupp/self.sample_rate)\n",
    "            hideal=hHigh-hLow\n",
    "            \n",
    "            self.band_pass[i,:]=Tensor(np.hamming(self.kernel_size))*Tensor(hideal)\n",
    "        \n",
    "        band_pass_filter=self.band_pass.to(self.device)\n",
    "\n",
    "        self.filters = (band_pass_filter).view(self.out_channels, 1, self.kernel_size)\n",
    "        \n",
    "        return F.conv1d(x, self.filters, stride=self.stride,\n",
    "                        padding=self.padding, dilation=self.dilation,\n",
    "                         bias=None, groups=1)\n",
    "\n",
    "\n",
    "        \n",
    "class Residual_block(nn.Module):\n",
    "    def __init__(self, nb_filts, first = False):\n",
    "        super(Residual_block, self).__init__()\n",
    "        self.first = first\n",
    "        \n",
    "        if not self.first:\n",
    "            self.bn1 = nn.BatchNorm1d(num_features = nb_filts[0])\n",
    "        \n",
    "        self.lrelu = nn.LeakyReLU(negative_slope=0.3)\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels = nb_filts[0],\n",
    "\t\t\tout_channels = nb_filts[1],\n",
    "\t\t\tkernel_size = 3,\n",
    "\t\t\tpadding = 1,\n",
    "\t\t\tstride = 1)\n",
    "        \n",
    "        self.bn2 = nn.BatchNorm1d(num_features = nb_filts[1])\n",
    "        self.conv2 = nn.Conv1d(in_channels = nb_filts[1],\n",
    "\t\t\tout_channels = nb_filts[1],\n",
    "\t\t\tpadding = 1,\n",
    "\t\t\tkernel_size = 3,\n",
    "\t\t\tstride = 1)\n",
    "        \n",
    "        if nb_filts[0] != nb_filts[1]:\n",
    "            self.downsample = True\n",
    "            self.conv_downsample = nn.Conv1d(in_channels = nb_filts[0],\n",
    "\t\t\t\tout_channels = nb_filts[1],\n",
    "\t\t\t\tpadding = 0,\n",
    "\t\t\t\tkernel_size = 1,\n",
    "\t\t\t\tstride = 1)\n",
    "            \n",
    "        else:\n",
    "            self.downsample = False\n",
    "        self.mp = nn.MaxPool1d(3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if not self.first:\n",
    "            out = self.bn1(x)\n",
    "            out = self.lrelu(out)\n",
    "        else:\n",
    "            out = x\n",
    "            \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn2(out)\n",
    "        out = self.lrelu(out)\n",
    "        out = self.conv2(out)\n",
    "        \n",
    "        if self.downsample:\n",
    "            identity = self.conv_downsample(identity)\n",
    "            \n",
    "        out += identity\n",
    "        out = self.mp(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class RawNet(nn.Module):\n",
    "    def __init__(self, d_args, device):\n",
    "        super(RawNet, self).__init__()\n",
    "\n",
    "        \n",
    "        self.device=device\n",
    "\n",
    "        self.Sinc_conv=SincConv(device=self.device,\n",
    "\t\t\tout_channels = d_args['filts'][0],\n",
    "\t\t\tkernel_size = d_args['first_conv'],\n",
    "                        in_channels = d_args['in_channels']\n",
    "        )\n",
    "        \n",
    "        self.first_bn = nn.BatchNorm1d(num_features = d_args['filts'][0])\n",
    "        self.selu = nn.SELU(inplace=True)\n",
    "        self.block0 = nn.Sequential(Residual_block(nb_filts = d_args['filts'][1], first = True))\n",
    "        self.block1 = nn.Sequential(Residual_block(nb_filts = d_args['filts'][1]))\n",
    "        self.block2 = nn.Sequential(Residual_block(nb_filts = d_args['filts'][2]))\n",
    "        d_args['filts'][2][0] = d_args['filts'][2][1]\n",
    "        self.block3 = nn.Sequential(Residual_block(nb_filts = d_args['filts'][2]))\n",
    "        self.block4 = nn.Sequential(Residual_block(nb_filts = d_args['filts'][2]))\n",
    "        self.block5 = nn.Sequential(Residual_block(nb_filts = d_args['filts'][2]))\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        self.fc_attention0 = self._make_attention_fc(in_features = d_args['filts'][1][-1],\n",
    "            l_out_features = d_args['filts'][1][-1])\n",
    "        self.fc_attention1 = self._make_attention_fc(in_features = d_args['filts'][1][-1],\n",
    "            l_out_features = d_args['filts'][1][-1])\n",
    "        self.fc_attention2 = self._make_attention_fc(in_features = d_args['filts'][2][-1],\n",
    "            l_out_features = d_args['filts'][2][-1])\n",
    "        self.fc_attention3 = self._make_attention_fc(in_features = d_args['filts'][2][-1],\n",
    "            l_out_features = d_args['filts'][2][-1])\n",
    "        self.fc_attention4 = self._make_attention_fc(in_features = d_args['filts'][2][-1],\n",
    "            l_out_features = d_args['filts'][2][-1])\n",
    "        self.fc_attention5 = self._make_attention_fc(in_features = d_args['filts'][2][-1],\n",
    "            l_out_features = d_args['filts'][2][-1])\n",
    "\n",
    "        self.bn_before_gru = nn.BatchNorm1d(num_features = d_args['filts'][2][-1])\n",
    "        self.gru = nn.GRU(input_size = d_args['filts'][2][-1],\n",
    "\t\t\thidden_size = d_args['gru_node'],\n",
    "\t\t\tnum_layers = d_args['nb_gru_layer'],\n",
    "\t\t\tbatch_first = True)\n",
    "\n",
    "        \n",
    "        self.fc1_gru = nn.Linear(in_features = d_args['gru_node'],\n",
    "\t\t\tout_features = d_args['nb_fc_node'])\n",
    "       \n",
    "        self.fc2_gru = nn.Linear(in_features = d_args['nb_fc_node'],\n",
    "\t\t\tout_features = d_args['nb_classes'],bias=True)\n",
    "\t\t\t\n",
    "       \n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, x, y = None):\n",
    "        \n",
    "        \n",
    "        nb_samp = x.shape[0]\n",
    "        len_seq = x.shape[1]\n",
    "        x=x.view(nb_samp,1,len_seq)\n",
    "        \n",
    "        x = self.Sinc_conv(x)    \n",
    "        x = F.max_pool1d(torch.abs(x), 3)\n",
    "        x = self.first_bn(x)\n",
    "        x =  self.selu(x)\n",
    "        \n",
    "        x0 = self.block0(x)\n",
    "        y0 = self.avgpool(x0).view(x0.size(0), -1) # torch.Size([batch, filter])\n",
    "        y0 = self.fc_attention0(y0)\n",
    "        y0 = self.sig(y0).view(y0.size(0), y0.size(1), -1)  # torch.Size([batch, filter, 1])\n",
    "        x = x0 * y0 + y0  # (batch, filter, time) x (batch, filter, 1)\n",
    "        \n",
    "\n",
    "        x1 = self.block1(x)\n",
    "        y1 = self.avgpool(x1).view(x1.size(0), -1) # torch.Size([batch, filter])\n",
    "        y1 = self.fc_attention1(y1)\n",
    "        y1 = self.sig(y1).view(y1.size(0), y1.size(1), -1)  # torch.Size([batch, filter, 1])\n",
    "        x = x1 * y1 + y1 # (batch, filter, time) x (batch, filter, 1)\n",
    "\n",
    "        x2 = self.block2(x)\n",
    "        y2 = self.avgpool(x2).view(x2.size(0), -1) # torch.Size([batch, filter])\n",
    "        y2 = self.fc_attention2(y2)\n",
    "        y2 = self.sig(y2).view(y2.size(0), y2.size(1), -1)  # torch.Size([batch, filter, 1])\n",
    "        x = x2 * y2 + y2 # (batch, filter, time) x (batch, filter, 1)\n",
    "\n",
    "        x3 = self.block3(x)\n",
    "        y3 = self.avgpool(x3).view(x3.size(0), -1) # torch.Size([batch, filter])\n",
    "        y3 = self.fc_attention3(y3)\n",
    "        y3 = self.sig(y3).view(y3.size(0), y3.size(1), -1)  # torch.Size([batch, filter, 1])\n",
    "        x = x3 * y3 + y3 # (batch, filter, time) x (batch, filter, 1)\n",
    "\n",
    "        x4 = self.block4(x)\n",
    "        y4 = self.avgpool(x4).view(x4.size(0), -1) # torch.Size([batch, filter])\n",
    "        y4 = self.fc_attention4(y4)\n",
    "        y4 = self.sig(y4).view(y4.size(0), y4.size(1), -1)  # torch.Size([batch, filter, 1])\n",
    "        x = x4 * y4 + y4 # (batch, filter, time) x (batch, filter, 1)\n",
    "\n",
    "        x5 = self.block5(x)\n",
    "        y5 = self.avgpool(x5).view(x5.size(0), -1) # torch.Size([batch, filter])\n",
    "        y5 = self.fc_attention5(y5)\n",
    "        y5 = self.sig(y5).view(y5.size(0), y5.size(1), -1)  # torch.Size([batch, filter, 1])\n",
    "        x = x5 * y5 + y5 # (batch, filter, time) x (batch, filter, 1)\n",
    "\n",
    "        x = self.bn_before_gru(x)\n",
    "        x = self.selu(x)\n",
    "        x = x.permute(0, 2, 1)     #(batch, filt, time) >> (batch, time, filt)\n",
    "        self.gru.flatten_parameters()\n",
    "        x, _ = self.gru(x)\n",
    "        x = x[:,-1,:]\n",
    "        x = self.fc1_gru(x)\n",
    "        x = self.fc2_gru(x)\n",
    "        output=self.logsoftmax(x)\n",
    "      \n",
    "        return output\n",
    "        \n",
    "        \n",
    "\n",
    "    def _make_attention_fc(self, in_features, l_out_features):\n",
    "\n",
    "        l_fc = []\n",
    "        \n",
    "        l_fc.append(nn.Linear(in_features = in_features,\n",
    "\t\t\t        out_features = l_out_features))\n",
    "\n",
    "        \n",
    "\n",
    "        return nn.Sequential(*l_fc)\n",
    "\n",
    "\n",
    "    def _make_layer(self, nb_blocks, nb_filts, first = False):\n",
    "        layers = []\n",
    "        #def __init__(self, nb_filts, first = False):\n",
    "        for i in range(nb_blocks):\n",
    "            first = first if i == 0 else False\n",
    "            layers.append(Residual_block(nb_filts = nb_filts,\n",
    "\t\t\t\tfirst = first))\n",
    "            if i == 0: nb_filts[0] = nb_filts[1]\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def summary(self, input_size, batch_size=-1, device=\"cuda\", print_fn = None):\n",
    "        if print_fn == None: printfn = print\n",
    "        model = self\n",
    "        \n",
    "        def register_hook(module):\n",
    "            def hook(module, input, output):\n",
    "                class_name = str(module.__class__).split(\".\")[-1].split(\"'\")[0]\n",
    "                module_idx = len(summary)\n",
    "                \n",
    "                m_key = \"%s-%i\" % (class_name, module_idx + 1)\n",
    "                summary[m_key] = OrderedDict()\n",
    "                summary[m_key][\"input_shape\"] = list(input[0].size())\n",
    "                summary[m_key][\"input_shape\"][0] = batch_size\n",
    "                if isinstance(output, (list, tuple)):\n",
    "                    summary[m_key][\"output_shape\"] = [\n",
    "\t\t\t\t\t\t[-1] + list(o.size())[1:] for o in output\n",
    "\t\t\t\t\t]\n",
    "                else:\n",
    "                    summary[m_key][\"output_shape\"] = list(output.size())\n",
    "                    if len(summary[m_key][\"output_shape\"]) != 0:\n",
    "                        summary[m_key][\"output_shape\"][0] = batch_size\n",
    "                        \n",
    "                params = 0\n",
    "                if hasattr(module, \"weight\") and hasattr(module.weight, \"size\"):\n",
    "                    params += torch.prod(torch.LongTensor(list(module.weight.size())))\n",
    "                    summary[m_key][\"trainable\"] = module.weight.requires_grad\n",
    "                if hasattr(module, \"bias\") and hasattr(module.bias, \"size\"):\n",
    "                    params += torch.prod(torch.LongTensor(list(module.bias.size())))\n",
    "                summary[m_key][\"nb_params\"] = params\n",
    "                \n",
    "            if (\n",
    "\t\t\t\tnot isinstance(module, nn.Sequential)\n",
    "\t\t\t\tand not isinstance(module, nn.ModuleList)\n",
    "\t\t\t\tand not (module == model)\n",
    "\t\t\t):\n",
    "                hooks.append(module.register_forward_hook(hook))\n",
    "                \n",
    "        device = device.lower()\n",
    "        assert device in [\n",
    "\t\t\t\"cuda\",\n",
    "\t\t\t\"cpu\",\n",
    "\t\t], \"Input device is not valid, please specify 'cuda' or 'cpu'\"\n",
    "        \n",
    "        if device == \"cuda\" and torch.cuda.is_available():\n",
    "            dtype = torch.cuda.FloatTensor\n",
    "        else:\n",
    "            dtype = torch.FloatTensor\n",
    "        if isinstance(input_size, tuple):\n",
    "            input_size = [input_size]\n",
    "        x = [torch.rand(2, *in_size).type(dtype) for in_size in input_size]\n",
    "        summary = OrderedDict()\n",
    "        hooks = []\n",
    "        model.apply(register_hook)\n",
    "        model(*x)\n",
    "        for h in hooks:\n",
    "            h.remove()\n",
    "            \n",
    "        print_fn(\"----------------------------------------------------------------\")\n",
    "        line_new = \"{:>20}  {:>25} {:>15}\".format(\"Layer (type)\", \"Output Shape\", \"Param #\")\n",
    "        print_fn(line_new)\n",
    "        print_fn(\"================================================================\")\n",
    "        total_params = 0\n",
    "        total_output = 0\n",
    "        trainable_params = 0\n",
    "        for layer in summary:\n",
    "            # input_shape, output_shape, trainable, nb_params\n",
    "            line_new = \"{:>20}  {:>25} {:>15}\".format(\n",
    "\t\t\t\tlayer,\n",
    "\t\t\t\tstr(summary[layer][\"output_shape\"]),\n",
    "\t\t\t\t\"{0:,}\".format(summary[layer][\"nb_params\"]),\n",
    "\t\t\t)\n",
    "            total_params += summary[layer][\"nb_params\"]\n",
    "            total_output += np.prod(summary[layer][\"output_shape\"])\n",
    "            if \"trainable\" in summary[layer]:\n",
    "                if summary[layer][\"trainable\"] == True:\n",
    "                    trainable_params += summary[layer][\"nb_params\"]\n",
    "            print_fn(line_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c65394-9dcd-4ddd-9ce8-b62b9c66f51f",
   "metadata": {},
   "source": [
    "You can get pretrained weights from here : https://github.com/asvspoof-challenge/2021/tree/main/LA/Baseline-RawNet2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788133b7-83b9-49d1-ac64-1d106765fec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'  \n",
    "\n",
    "d_args ={\n",
    "  'nb_samp': 64600,\n",
    "  'first_conv': 1024,   # no. of filter coefficients \n",
    "  'in_channels': 1,\n",
    "  'filts': [20, [20, 20], [20, 128], [128, 128]], # no. of filters channel in residual blocks\n",
    "  'blocks': [2, 4],\n",
    "  'nb_fc_node': 1024,\n",
    "  'gru_node': 1024,\n",
    "  'nb_gru_layer': 3,\n",
    "  'nb_classes': 2\n",
    "}\n",
    "\n",
    "model = RawNet(d_args,device).to(device)\n",
    "checkpoint_path = \"path_to_checkpoint\"\n",
    "model.load_state_dict(torch.load(checkpoint_path))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32deaa8-96d2-42d7-be14-c6586c09f8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(train_loader, model, lr, optimizer, device):\n",
    "    running_loss = 0.0\n",
    "    num_correct = 0\n",
    "    num_total = 0\n",
    "    model.train()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for i, (batch_x, batch_y) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_size = batch_x.size(0)\n",
    "        running_loss += loss.item() * batch_size\n",
    "\n",
    "        _, preds = outputs.max(dim=1)\n",
    "        num_correct += (preds == batch_y).sum().item()\n",
    "        num_total += batch_size\n",
    "\n",
    "        if (i + 1) % 10 == 0:\n",
    "            acc = num_correct / num_total * 100\n",
    "            print(f\"\\r\\tBatch {i+1} - Accuracy: {acc:.2f}%\", end=\"\", flush=True)\n",
    "\n",
    "    epoch_loss = running_loss / num_total\n",
    "    epoch_acc = num_correct / num_total * 100\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "num_epochs = 30\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "\n",
    "    running_loss, train_accuracy = train_epoch(train_loader, model, 0.001, optimizer, device)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {running_loss:.4f}, Accuracy: {train_accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
